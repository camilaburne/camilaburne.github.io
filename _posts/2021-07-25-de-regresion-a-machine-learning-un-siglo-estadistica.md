---
layout: post_es
categories: "es"
title: "De regresi√≥n a Machine Learning: Dos siglos de Estad√≠stica"
date: 2021-07-25
tags: stats
desc: "Hoy ML es ... pero empez√≥ 200 a√±os atr√°s con min cua"
---

üößüöß Sitio en construccion üößüöß

### Contenidos

| **Year**    | **Publication**                     | **Author**                         |
| 1805        | [M√≠nimos Cuadrados](#ls)            | Legendre & Gauss                   |
| 1812,1901   | [Teorema Central del L√≠mite](#tcl)  | Laplace, Lyapunov                  |
| 18--        | [Regresion al promedio](#reg)       | Galton                             |
| 1907        | [T de Student](#t)                  | William Gosset, "Student"          |
| 1918        | [ANOVA](#fisher)                    | Fisher                             |
| 1936        | [An√°lisis Discriminante](#fisher)   | Fisher                             |
| 1940        | [Regresion Logistica](#logreg)      | AAVV                               |
| 1970        | [Modelos Lineales Gralizados](#glm) | Nelder & Wedderburn                |
| 1980        | [Arboles de decision](#tree)        | Breiman, Friedman, Olshen & Stone  |
| 1993        | [R software](#r)                    | Ross Ihaka & Robert Gentleman      |



Links con info:
[Gauss vs Lagrange](#https://projecteuclid.org/journals/annals-of-statistics/volume-9/issue-3/Gauss-and-the-Invention-of-Least-Squares/10.1214/aos/1176345451.full)
[History of Statistics - video](https://www.youtube.com/watch?v=zhLY4Vu_TEQ)
[Historia de R - video](https://www.youtube.com/watch?v=STihTnVSZnI)


## M√≠nimos Cuadrados <a name="ls"></a>

El primer hito en la historia es el m√°s dram√°tico, porque el desarrollo de m√≠nimos cuadrados se disputa entre dos autores. Hoy se acepta que Gauss descubri√≥ m√≠nimos cuadrados primero, pero Lagendre le gan√≥ en la publicaci√≥n {1}. Una de las evidencias a favor de que Gauss lo invent√≥ primero, fue que en 1799 utiliz√≥ el m√©todo de m√≠nimos cuadrados para calcular la eliplicidad de la Tierra. De igual modo, fue gracias a Lagendre que se populariz√≥ - tan r√°pidamente que en 10 a√±os se estaba usando en varios pa√≠ses de Europa.

<img src="/images/gauss_legendre.jpg" class=rightimg>


Una primera demostraci√≥n de la fuerza del m√©todo de Gauss se produjo cuando se utiliz√≥ para predecir la ubicaci√≥n futura del asteroide reci√©n descubierto Ceres. El 1 de enero de 1801, el astr√≥nomo italiano Giuseppe Piazzi descubri√≥ Ceres y pudo seguir su trayectoria durante 40 d√≠as antes de que se perdiera en el resplandor del sol. Bas√°ndose en estos datos, los astr√≥nomos deseaban determinar la ubicaci√≥n de Ceres despu√©s de que emergiera detr√°s del sol sin resolver las complicadas ecuaciones no lineales de Kepler del movimiento planetario. Las √∫nicas predicciones que permitieron con √©xito al astr√≥nomo h√∫ngaro Franz Xaver von Zach reubicar Ceres fueron las realizadas por Gauss, de 24 a√±os, utilizando an√°lisis de m√≠nimos cuadrados.

El m√©todo de m√≠nimos cuadrados es uno de los hitos principales en la historia de la ciencia de datos porque por primera vez se acepta de manera masiva la idea de ajustar una funci√≥n a datos observados. Adem√°s, este m√©todo pod√≠a aplicarse a cualquier disciplina, no estaba limitado a la astronom√≠a y geodesia como muchos de los avances de los autores en esa √©poca.


## Teorema Central del L√≠mite <a name="tcl"></a>


At the beginning of the nineteenth century, Legendre and Gauss published papers on the method of least squares, which implemented the earliest form of what is now known as linear regression. The approach was first successfully applied to prob- lems in astronomy.

<img src="/images/laplace_lyapunov.jpg" class=rightimg>


Linear regression is used for predicting quantitative values, such as an individual‚Äôs salary. In order to predict qualitative values, such as whether a patient survives or dies, or whether the stock market in- creases or decreases, Fisher proposed linear discriminant analysis in 1936. In the 1940‚Äôs, various authors put forth an alternative approach, logistic regression. In the early 1970‚Äôs, Nelder and Wedderburn coined the term generalized linear models for an entire class of statistical learning methods that include both linear and logistic regression as special cases.
By the end of the 1970‚Äôs, many more techniques for learning from data were available. However, they were almost exclusively linear methods, be- cause fitting non-linear relationships was computationally infeasible at the time. By the 1980‚Äôs, computing technology had finally improved sufficiently that non-linear methods were no longer computationally prohibitive. In mid 1980‚Äôs Breiman, Friedman, Olshen and Stone introduced classification and regression trees, and were among the first to demonstrate the power of a detailed practical implementation of a method, including cross-validation for model selection. Hastie and Tibshirani coined the term generalized addi- tive models in 1986 for a class of non-linear extensions to generalized linear models, and also provided a practical software implementation.

## Regresion a la media <a name="reg"></a>
Aca va Galton

## T de Student <a name="t"></a>

<blockquote>
¬´ Aunque es bien sabido que el m√©todo de usar la curva normal solo es confiable cuando la muestra es "grande", nadie nos ha dicho todav√≠a muy claramente d√≥nde debe trazarse el l√≠mite entre muestras "grandes" y "peque√±as" ¬ª Student, 1908
</blockquote>

Quiero decir que: cualquiera iniciando un curso en Estad√≠stica se topa con los test de media,
y se pregunta que por qu√© a veces usamos la T y a veces la Normal; y qui√©n decide el tama√±o de la muestra -- estas preguntas se las hizo Student hace 100 a√±os, y al resolverla invent√≥ una distribuci√≥n, la T de Student. "Student" fue el pseud√≥nimo que us√≥, ya que en Guinness no le dejaron usar su nombre, por medio a que la competencia usara sus an√°lisis para su producci√≥n.

Las publicaciones de Student fueron valoradas por Fisher, con quien intercambi√≥ correspondencia en m√°s de 150 cartas.

Again, although it is well known that the method of using the normal curve is only trustworthy when the sample is
"large," no one has yet told us very clearly where the limit between "l large " and " small " samples is to be drawn.

Esto es un hito tambi√©n, desde el 3500 a.C. la estad√≠stica estuvo asociada a censos poblacionales, desde el siglo 19 a la astronom√≠a y geodesia; pero a partir de T de Student, la teor√≠a estad√≠stica se pone al servicio de la industria y de experimentos a peque√±a escala.

## La era Fisher

<img src="/images/fisher_laurel.jpg" class=rightimg>


Fisher cre√≥, casi que solo, las bases para la estad√≠stica moderna. √âl fue el primero en hablar de Variancia, invent√≥ el an√°lisis de la variancia (ANOVA), el test de significancia! la hip√≥tesis nula, la alternativa; la distribuci√≥n y el test F, con su nombre, como el text exacto de Fisher, el modelo de efectos aleatorios, junto a otros 30 art√≠culos de wikipedia de test, definiciones y m√©tidos que llevan su nombre. As√≠ que no es exagerado el t√≠tulo de "Estad√≠stico del siglo 20"

## R  <a name="r"></a>
El √∫ltimo de la lista es R, y ac√° lo dejo porque esto sucedi√≥ despu√©s de que yo naciera y ya me sent√≠ vieja.

## Pol√©mica

- Eugenics: Fisher y Pearson defend√≠an la "supremac√≠a" de la raza blanca.




-------------
Nightingale died 10 years afeter the 20th centurt began, on the verge of a modern era.
The 20th century not only opened up an impressive consolidation of the mathematical theory of
statistics and probability theory, but it also totally transformed the amounts and kinds of numerical information available in virtually every area of human endeavor.
The rise of numbers had carried the world to the brink of a new digital age of information.
